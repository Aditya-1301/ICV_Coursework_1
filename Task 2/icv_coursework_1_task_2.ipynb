{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759e70f-5bb3-4e35-82cd-794985c270c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e1c9e-4b0a-41fb-bea2-2def948a4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d43355-5c0c-43ff-a1fe-678e0d25cd1a",
   "metadata": {},
   "source": [
    "# Tasks A and B\n",
    "\n",
    "<!-- For this task I began by implementing the convolution filter for a grayscale image to get an idea for how to approach the task. To do this I began by reading the image using `plt.imread` function and then use `cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)` to create a grayscale version of the image.  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449383e1-ee3d-4d46-a1e2-5caa346da967",
   "metadata": {},
   "source": [
    "## Applying a Convolution Filter on a grayscale image\n",
    "\n",
    "Here the ratios by which I multiply is based on this article: [NTSC Formula for Grayscale](https://support.ptc.com/help/mathcad/r10.0/en/index.html#page/PTC_Mathcad_Help/example_grayscale_and_color_in_images.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733bc2dd-d219-4607-9d10-7b585a207fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_to_grayscale(image):\n",
    "    w, h, c = image.shape\n",
    "    grayimg = np.zeros((w,h))\n",
    "    grayimg = (0.299*image[:,:,0] + 0.587*image[:,:,1] + 0.114*image[:,:,2])\n",
    "    return grayimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bab0ea1-20f7-4519-84db-ac1b27836706",
   "metadata": {},
   "source": [
    "Here I divide each kernel by its sum to get the average intensity kernel for each size (3x3 to 7x7). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45a1b95-2585-4ff0-8243-d25db6cd7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(\"car-1.jpg\")\n",
    "img = ICV_to_grayscale(image)\n",
    "## I have defined kernels of different sizes to experiment and see how they change the effect of the filter\n",
    "\n",
    "kernel_3 = np.array([\n",
    "    [1,1,1],\n",
    "    [1,1,1],\n",
    "    [1,1,1],\n",
    "])\n",
    "avg_kernel_3 = kernel_3/np.sum(kernel_3)\n",
    "\n",
    "kernel_5 = np.array([\n",
    "    [1,1,1,1,1],\n",
    "    [1,1,1,1,1],\n",
    "    [1,1,1,1,1],\n",
    "    [1,1,1,1,1],\n",
    "    [1,1,1,1,1],\n",
    "])\n",
    "avg_kernel_5 = kernel_5/np.sum(kernel_5)\n",
    "\n",
    "kernel_7 = np.array([\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "    [1,1,1,1,1,1,1],\n",
    "])\n",
    "avg_kernel_7 = kernel_7/np.sum(kernel_7)\n",
    "print(avg_kernel_3, avg_kernel_5, avg_kernel_7)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbc01b5-2107-483b-a6ed-33a65842b19e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ICV_convolution_filtering_grayscale(image, kernel):\n",
    "    \"\"\"\n",
    "    Applies a convolution kernel on a greyscale image.\n",
    "\n",
    "    Parameters:\n",
    "    image -> 2D numpy array\n",
    "    kernel -> 2D numpy array (usually with shapes (3,3), (5,5) or (7,7))\n",
    "\n",
    "    Returns:\n",
    "    2D numpy array (Image with filter applied to it)\n",
    "    \"\"\"\n",
    "    width, height = image.shape[:2] # Get width and height from image shape\n",
    "    new_image = np.zeros((width, height)) # create new image array\n",
    "    k_w, k_h = kernel.shape[:2] # Get width and height of convolution kernel\n",
    "\n",
    "    ## I pad the image with zeroes to half the size of the \n",
    "    ## kernel's width/height before applying the filter\n",
    "    pad_width, pad_height = (k_w-1)//2, (k_h-1)//2 \n",
    "\n",
    "    ## The padded image is slightly larger to allow the kernels's to affect all pixels in the image\n",
    "    ## The image is padded at the top, bottom, left and right edges\n",
    "    padded_image = np.zeros((width + 2 * pad_width, height + 2 * pad_height))\n",
    "\n",
    "    ## Put the original image back into the larger padded array\n",
    "    padded_image[pad_width:pad_width + width, pad_height:pad_height + height] = image\n",
    "\n",
    "    ## When iterating over the image to ensure that the kernel is properly applied\n",
    "    ## and so we don't get out of bounds errors, I iterate till width/height -pad_width/pad_height\n",
    "    for i in range(width-pad_width):\n",
    "        for j in range(height-pad_height):\n",
    "            ## Apply the kernel on each pixel of the original image \n",
    "            ## and store the results in the new_image array\n",
    "            new_image[i+1, j+1] = np.sum(kernel * padded_image[i:i+k_w, j:j+k_h])\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d9b64-757c-4a79-a807-12720a482c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_gray = ICV_convolution_filtering_grayscale(img, avg_kernel_3)\n",
    "# print(filtered_img_gray, filtered_img_gray.shape)\n",
    "plt.imshow(filtered_img_gray, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbe26a0-0f0b-4552-937a-992b73620867",
   "metadata": {},
   "source": [
    "## Different attempts at trying to implement the same for an RGB image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c914fc-f24d-4ea3-9217-44e93eb2b660",
   "metadata": {},
   "source": [
    "### Attempt 1:\n",
    "\n",
    "This version works but suffers from the boundary problem. Each time a convolution is applied, the image shrinks by half the size of the kernel in its width and height. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d831c228-641d-4a7e-89c3-a902e1f0b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_convolution_filtering_rgb(image, kernel):\n",
    "    \"\"\"\n",
    "    Applies a convolution kernel on a rgb image. (This implementation suffers from the border problem)\n",
    "\n",
    "    Parameters:\n",
    "    image -> 2D numpy array\n",
    "    kernel -> 2D numpy array (usually with shapes (3,3), (5,5) or (7,7))\n",
    "\n",
    "    Returns:\n",
    "    2D numpy array (Image with filter applied to it)\n",
    "    \"\"\"\n",
    "    width, height, channels = image.shape # Get width and height from image shape\n",
    "    k_w, k_h = kernel.shape[:2] # get kernel shape\n",
    "    print(image.shape)\n",
    "    new_image = np.zeros((width-k_w+1, height-k_h+1, channels))\n",
    "    for c in range(channels):\n",
    "        for i in range(width-k_w+1):\n",
    "            for j in range(height-k_h+1):\n",
    "                new_image[i, j, c] = np.sum(kernel * image[i:i+k_w, j:j+k_h, c], axis=(0,1))\n",
    "    return new_image.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9aeb74-3513-45b2-81b0-602bb8d8298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = ICV_convolution_filtering_rgb(image, avg_kernel_3)\n",
    "print(filtered_img, filtered_img.shape)\n",
    "plt.imshow(filtered_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0c92e-e4c9-4a0b-9e02-f5df9596c639",
   "metadata": {},
   "source": [
    "### Attempt 2 :\n",
    "\n",
    "Here I try to pad the image, but I overflowed/underflowed the image channel buffers. The image produced from it is quite dark and thus to see the result I don't divide filtered array by the sum of the kernel to obtain a brighter image. The resulting image has an interesting effect where there are colors all over the place and its hard to properly distinguish the subject of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f8154-3dd8-460b-a4f6-890b0a9a9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_convolution_filtering_rgb_2(image, kernel):\n",
    "    \"\"\"\n",
    "    Applies a convolution kernel on a rgb image. (Failed attempt)\n",
    "\n",
    "    Parameters:\n",
    "    image -> 2D numpy array\n",
    "    kernel -> 2D numpy array (usually with shapes (3,3), (5,5) or (7,7))\n",
    "\n",
    "    Returns:\n",
    "    2D numpy array (Image with filter applied to it)\n",
    "    \"\"\" \n",
    "    width, height, channels = image.shape # Get width and height from image shape\n",
    "    k_w, k_h = kernel.shape[:2] # Get kernel shape\n",
    "    pad_width, pad_height = (k_w-1)//2, (k_h-1)//2\n",
    "    \n",
    "    padded_image = np.zeros((width + 2 * pad_width, height + 2 * pad_height, channels))\n",
    "    padded_image[pad_width:pad_width + width, pad_height:pad_height + height, :] = image\n",
    "\n",
    "    new_image = np.zeros_like(image)\n",
    "    \n",
    "    for c in range(channels):\n",
    "        for i in range(width-pad_width):\n",
    "            for j in range(height-pad_height):\n",
    "                new_image[i, j, c] = np.sum(kernel * padded_image[i:i+k_w, j:j+k_h, c])\n",
    "    \n",
    "    return new_image.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdcf96-257a-44ca-9708-e125172631b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the reason mentioned in the MD section I have chosen to use kernel_3 instead of avg_kernel_3 for this example\n",
    "filtered_img_rgb_2 = ICV_convolution_filtering_rgb_2(image, kernel_3)\n",
    "# print(filtered_img_rgb_2, filtered_img_rgb_2.shape)\n",
    "plt.imshow(filtered_img_rgb_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7045c19-2993-44e6-bce4-cf240597f2b0",
   "metadata": {},
   "source": [
    "### Attempt 3: Finally successful!\n",
    "\n",
    "After 2 failed attempts, I finally managed to apply the filter while retaining the image's original dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9bcf55-bbb0-48ce-89ed-5c52f31fedae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_convolution_filtering_rgb_3(image, kernel):\n",
    "    width, height, channels = image.shape\n",
    "    k_w, k_h = kernel.shape[:2]\n",
    "\n",
    "    pad_width = k_w//2\n",
    "    pad_height = k_h//2\n",
    "    padded_image = np.zeros((width + 2 * pad_width, height + 2*pad_height, channels), dtype=image.dtype)\n",
    "\n",
    "    padded_image[ pad_width: pad_width + width,  pad_height:pad_height + height] = image\n",
    "    \n",
    "    # padding = 1\n",
    "    # padded_image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "    # padded_width, padded_height = padded_image.shape[:2]\n",
    "    new_image = np.zeros((width, height, channels))\n",
    "\n",
    "    ## Till this point everything is the same as the previous implementations\n",
    "    \n",
    "    for c in range(channels):\n",
    "        ## The size of the new image should be the same as the original and thus I iterate the same dimensions\n",
    "        ## as the original image\n",
    "        for i in range(width):\n",
    "            for j in range(height):\n",
    "                ## Here I take the sum across both rows and columns of the product\n",
    "                new_image[i, j, c] = np.sum(kernel * padded_image[i:i+k_w, j:j+k_h, c], axis=(0,1))\n",
    "    \n",
    "    return new_image.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682e946-2cbd-4369-8e1e-d80860857e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_rgb = ICV_convolution_filtering_rgb_3(image, avg_kernel_3) \n",
    "print(filtered_img_rgb.shape) # ,filtered_img_rgb)\n",
    "plt.imshow(filtered_img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c3f292-6533-4c3d-8acc-7f8b5b077ac4",
   "metadata": {},
   "source": [
    "### Experiments with Kernels larger than 3x3\n",
    "\n",
    "Here I tested how the different kernels behave in the event a larger kernel of size such as 5x5 or 7x7 is applied instead of the standard 3*3 kernel. Here I'm doing this with the function I created in my first attempt (convolution_filtering_rgb) to highlight how larger kernels would make the boundary problem significantly worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c6b503-c39f-4fd4-8c78-3ee6ac249dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = ICV_convolution_filtering_rgb(image, avg_kernel_5)\n",
    "print(\"Filtered Shape:\", filtered_img.shape)\n",
    "plt.imshow(filtered_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c4398-9c1c-41fc-b9b2-a9d5aa9fd4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = ICV_convolution_filtering_rgb(image, avg_kernel_7)\n",
    "print(\"Filtered Shape:\", filtered_img.shape)\n",
    "plt.imshow(filtered_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514706d9-3c27-4e41-b4cc-fe1129f75a85",
   "metadata": {},
   "source": [
    "As can be seen in the 2 examples above applying a bigger filter just accelarates the results of the boundary problem, with the image losing between 5 and 7 pixels each time the filter is applied. This would be especially detrimental for images with smaller dimensions like the ones in Dataset A which have dimensions 256*256."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c0705-4af9-47d6-ae56-94a3750de89a",
   "metadata": {},
   "source": [
    "### Original Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5158f-8632-4417-bad7-d26cd2df2e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4645878-f675-4da8-a890-3c1ecac2ec4e",
   "metadata": {},
   "source": [
    "### Averaged Image (Kernel (5x5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd369cd-0493-44c3-8a41-b7d06a0ee83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img = ICV_convolution_filtering_rgb(image, avg_kernel_5)\n",
    "print(\"Filtered Shape:\", filtered_img.shape)\n",
    "plt.imshow(filtered_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd0bd52-082c-40e8-8cbc-2485c8ab24f6",
   "metadata": {},
   "source": [
    "# Task C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f820685-f0fe-4d28-b2ed-d87da5a59538",
   "metadata": {},
   "source": [
    "## Applying Gaussian and Laplace Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29753f-5b69-4546-8523-bf3bd67cb2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur Filter Kernel\n",
    "kernel_a = np.array([\n",
    "    [1,2,1],\n",
    "    [2,4,2],\n",
    "    [1,2,1],\n",
    "])\n",
    "\n",
    "\n",
    "# Laplace Filter Kernel\n",
    "kernel_b = np.array([\n",
    "    [0,1,0],\n",
    "    [1,-4,1],\n",
    "    [0,1,0],\n",
    "])\n",
    "\n",
    "\n",
    "# I also have the Sobel filter Kernel which I experimented with\n",
    "kernel_c = np.array([\n",
    "    [1,0,-1],\n",
    "    [1,0,-1],\n",
    "    [1,0,-1],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1c516-8be3-464b-8c60-d5c792d83565",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Gaussian Filter (A)\n",
    "filtered_img_a = ICV_convolution_filtering_rgb_3(image, kernel_a)//np.sum(kernel_a)\n",
    "print(\"Filtered Result Shape: \", filtered_img_a.shape)\n",
    "plt.imshow(filtered_img_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efc9da9-8e0a-49fc-9945-cc26d9e7731a",
   "metadata": {},
   "source": [
    "## Conversion and Thresholding\n",
    "\n",
    "This is a helper function for the Laplace filter in Task C. This helps the resulting image to have sharper edges and uses a thresolding method and converts all pixel values in the image above a certain threshold (here I set it to around 50% of max intensity) to 255 and everything below it to 0. This also helps convert images with invalid pixel values (> 255 or < 0) to something which is still within the acceptable range. Some filters such as the laplace filter, when applied result in filters which create pixel values greater than 255 or negative pixel values. This can't directly be displayed so the image results need to converted for the best results. Jupyter Hub handles this as well, but its good practice to remove unexpected behaviour and keep the pixel values within the acceptable range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82f43d4-b700-4ff1-a232-3fc72a2fb71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_clip_image_rgb(image):\n",
    "    width, height, channels = image.shape\n",
    "    threshold = 122 # 50 % of max intensity (255)\n",
    "    for c in range(channels):\n",
    "        for i in range(width):\n",
    "            for j in range(width):\n",
    "                if image[i][j][c] < 0:\n",
    "                    image[i][j][c] = 0\n",
    "                elif image[i][j][c] > threshold: \n",
    "                    image[i][j][c] = 255\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd8e266-abdd-4b45-960b-dac74be1516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Laplace Filter (B)\n",
    "filtered_img_b = ICV_convolution_filtering_rgb_3(image, kernel_b)\n",
    "print(\"Filtered Result Shape:\", filtered_img_b.shape)\n",
    "## Here I print the max and min pixel value to show why we need to clip the filtered image \n",
    "print(\"Max filtered pixel value: \", np.amax(filtered_img_b), \" | Min filtered pixel value: \", np.amin(filtered_img_b))\n",
    "filtered_img_b = ICV_clip_image_rgb(filtered_img_b)\n",
    "plt.imshow(filtered_img_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8663ecd5-ae30-47df-b17f-6f1db9a4a4ba",
   "metadata": {},
   "source": [
    "# Task D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5b6e6-5ddc-4356-bc23-46cd3fe3c0b1",
   "metadata": {},
   "source": [
    "### Subtask 1\n",
    "\n",
    "For task C I had applied the filter A on the image already so use its result here directly (filtered_img_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc6f2d-92d4-4250-af7e-3aa75a2ccdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_a_a = ICV_convolution_filtering_rgb_3(filtered_img_a, kernel_a)//np.sum(kernel_a) \n",
    "print(\"Filtered Result Shape:\", filtered_img_a_a.shape)\n",
    "plt.imshow(filtered_img_a_a, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd74d020-765d-4247-ab74-523dbc845359",
   "metadata": {},
   "source": [
    "### Subtask 2 ((Applying Filter A followed Filter B))\n",
    "Same as in the previous cell, I use the result of applying kernel_a and kernel_b on the image here directly (filtered_img_a and filtered_image_b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508985d1-9ff6-4be6-a469-77ee6006ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_a_b = ICV_convolution_filtering_rgb_3(filtered_img_a, kernel_b)\n",
    "print(\"Filtered Result Shape:\",  filtered_img_a_b.shape)\n",
    "filtered_img_a_b = ICV_clip_image_rgb(filtered_img_a_b)\n",
    "plt.imshow(filtered_img_a_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb5a2e-359a-43f0-a779-f8090b97acb3",
   "metadata": {},
   "source": [
    "### Subtask 3 (Applying Filter B followed Filter A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abc0af-a95a-447c-854b-991fa7a91a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_img_b_a = ICV_convolution_filtering_rgb_3(filtered_img_b, kernel_a)//np.sum(kernel_a)\n",
    "print(\"Filtered Result Shape:\",  filtered_img_b_a.shape)\n",
    "plt.imshow(filtered_img_b_a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

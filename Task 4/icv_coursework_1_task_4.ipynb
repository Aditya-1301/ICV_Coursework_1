{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f366b7-847b-4763-ba34-d1d5e227469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef132471-b2b1-4a2c-ae65-5cb78ae7cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ebb3a2-6b6a-44c4-9ac8-1b4074d289d9",
   "metadata": {},
   "source": [
    "# Task A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b616b6ef",
   "metadata": {},
   "source": [
    "Grayscale method was take from question 2's implementation. Here the ratios by which I multiply is based on this article: [NTSC Formula for Grayscale](https://support.ptc.com/help/mathcad/r10.0/en/index.html#page/PTC_Mathcad_Help/example_grayscale_and_color_in_images.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e141955-6673-40a8-a41d-634dd91cac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_to_grayscale(image):\n",
    "    w, h, c = image.shape\n",
    "    grayimg = np.zeros((w,h))\n",
    "    grayimg = (0.299*image[:,:,0] + 0.587*image[:,:,1] + 0.114*image[:,:,2])\n",
    "    return grayimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801b9547",
   "metadata": {},
   "source": [
    "## Utility Functions for Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5060cf1-06e4-40bf-9060-c6e58f333c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_divide_into_non_overlapping_windows(image, window_size):\n",
    "    \"\"\"\n",
    "    Takes an image and divides it into windows of dimension window_size x window_size\n",
    "\n",
    "    Parameters:\n",
    "    image -> List[List[int]]\n",
    "    window_size -> int\n",
    "\n",
    "    Returns:\n",
    "    List[ List[List[int]] ] (List of windows)\n",
    "    \"\"\"\n",
    "\n",
    "    width, height = image.shape\n",
    "    non_overlapping_windows = []\n",
    "    for i in range(0, width, window_size):\n",
    "        for j in range(0, height, window_size):\n",
    "            window = image[i:i+window_size, j:j+window_size]\n",
    "            non_overlapping_windows.append(window)\n",
    "    return non_overlapping_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa2a156-fe67-4106-9922-35cb43c231d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_lbp_grayscale(image):\n",
    "    \"\"\"\n",
    "    Takes an image and computes lbp codes for each pixel in the image. \n",
    "\n",
    "    Parameters:\n",
    "    image -> List[List[int]]\n",
    "\n",
    "    Returns:\n",
    "    new_image -> List[List[int]] \n",
    "    \"\"\"\n",
    "\n",
    "    def ICV_get_lbp_code(window):\n",
    "        \"\"\" \n",
    "        This function takes the 3x3 window matrix and then computes the LBP code for it. \n",
    "        Uses a string to build up the LBP code and then converts into a number. \n",
    "        \n",
    "        \n",
    "        Parameters: \n",
    "        window -> List[List[int]]\n",
    "\n",
    "        Returns:\n",
    "        int (base 10)\n",
    "        \"\"\"\n",
    "\n",
    "        lbp_code = \"\"\n",
    "        threshold = window[1][1] # center value acts as threshold\n",
    "        for i, w in enumerate(window.flatten()): # flatten the array to speed up computation\n",
    "            if i != 4: # in the flattened array, the center value in 3x3 matrix is at i = 4, so we skip it\n",
    "                lbp_code += \"1\" if w > threshold else \"0\"\n",
    "        return int(lbp_code, 2) # convert to base 10 number\n",
    "        \n",
    "    width, height = image.shape[:2]\n",
    "    new_image = np.zeros((width, height))\n",
    "    k_w, k_h = 3, 3\n",
    "\n",
    "    # To apply LBP to each pixel I pad the image\n",
    "    pad_width, pad_height = (k_w-1)//2, (k_h-1)//2 \n",
    "    padded_image = np.zeros((width + 2 * pad_width, height + 2 * pad_height))\n",
    "    padded_image[pad_width:pad_width + width, pad_height:pad_height + height] = image\n",
    "\n",
    "    for i in range(width-k_w+1):\n",
    "        for j in range(height-k_h+1):\n",
    "            # Get LBP code for each window\n",
    "            new_image[i+1, j+1] = ICV_get_lbp_code(padded_image[i:i+k_w, j:j+k_h])\n",
    "    return new_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b248586-e7e2-46ff-a5d0-d6e0e62cfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_grayscale_histogram(image, bins=256):\n",
    "    \"\"\"\n",
    "    Computes the raw and normalized histogram bins for an image\n",
    "\n",
    "    Parameters: \n",
    "    image -> List[List[int]]\n",
    "    bins -> int (optional)\n",
    "\n",
    "    Returns: \n",
    "    List[]\n",
    "    \"\"\"\n",
    "    height, width = image.shape\n",
    "    histogram = np.zeros(bins)\n",
    "    bin_width = 256 // bins\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            bindex = min(int(image[i, j]) // bin_width, bins - 1)\n",
    "            histogram[bindex] +=1\n",
    "    histogram_n = [i/max(histogram) for i in histogram if max(histogram) != 0]\n",
    "    return histogram, histogram_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0901210-863d-46d1-9d76-e2619d02e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_window_histograms(image, window_size):\n",
    "    \"\"\"\n",
    "    Generates winodw histograms for an image given a specific window size\n",
    "\n",
    "    Parameters:\n",
    "    image -> List[List[int]]\n",
    "    window_size -> int\n",
    "\n",
    "    Returns: List[List[int]]\n",
    "    \"\"\"\n",
    "    width, height = image.shape\n",
    "    if width % window_size != 0 or height % window_size != 0:\n",
    "        # window_size = np.gcd([width, height])\n",
    "        print(\"Warning: Image dimensions are not divisible by window size. Extra pixels may be ignored.\")\n",
    "    hists = []\n",
    "    for i in range(0, width, window_size):\n",
    "        for j in range(0, height, window_size):\n",
    "            window = image[i:i+window_size, j:j+window_size]\n",
    "            hists.append(ICV_grayscale_histogram(window))\n",
    "    return hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63c9f4d-1233-45d7-8e73-1a8cb945b89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = plt.imread(\"face-3.jpg\")\n",
    "image_g = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "plt.imshow(image_g, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcda7cf7-9dfe-4546-b333-c4e928987cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 64\n",
    "dinow = np.array(ICV_divide_into_non_overlapping_windows(image_g, window_size))\n",
    "dinow_lbp = []\n",
    "for i in dinow:\n",
    "    dinow_lbp.append(ICV_lbp_grayscale(i))\n",
    "dinow_lbp = np.array(dinow_lbp)\n",
    "print(dinow_lbp.shape, dinow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4247fd-b23d-45cc-a1ee-b2979f73bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping variables to aid with plotting the windows\n",
    "\n",
    "dinow = dinow.reshape(4, 4, 64, 64)\n",
    "dinow_lbp = dinow_lbp.reshape(4, 4, 64, 64)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(8, 8))\n",
    "axs[0][0].imshow(dinow[0][0], cmap=\"gray\")\n",
    "axs[0][0].set_title(\"W1\")\n",
    "axs[0][1].imshow(dinow_lbp[0][0], cmap=\"gray\")\n",
    "axs[0][1].set_title(\"W2\")\n",
    "axs[1][0].imshow(dinow[2][2], cmap=\"gray\")\n",
    "axs[1][0].set_title(\"W3\")\n",
    "axs[1][1].imshow(dinow_lbp[2][2], cmap=\"gray\")\n",
    "axs[1][1].set_title(\"LBP1\")\n",
    "axs[2][0].imshow(dinow[3][2], cmap=\"gray\")\n",
    "axs[2][0].set_title(\"LBP2\")\n",
    "axs[2][1].imshow(dinow_lbp[3][2], cmap=\"gray\")\n",
    "axs[2][1].set_title(\"LBP3\")\n",
    "fig.suptitle(\"Random Windows from face-3.jpg and its lbp counterparts\", fontsize=16)\n",
    "\n",
    "for axs in axs.flat:\n",
    "    axs.axis('off')\n",
    "\n",
    "plt.savefig(\"Random Windows from face-3.jpg and its lbp counterparts.png\")\n",
    "plt.show()\n",
    "\n",
    "fig1, axs = plt.subplots(4, 4, figsize=(5, 5), gridspec_kw={'hspace': 0.1, 'wspace': 0.1})\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i][j].imshow(dinow_lbp[i][j], cmap=\"gray\")\n",
    "        \n",
    "for ax in axs.flat:\n",
    "    ax.axis('off')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ef95a-1cc3-42ce-a34f-a436cc19871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dinow_lbp_hists = []\n",
    "dinow_lbp_hists_n = []\n",
    "for i in range(dinow_lbp.shape[0]):\n",
    "    for j in range(dinow_lbp.shape[1]):\n",
    "        hist, hist_n = ICV_grayscale_histogram(dinow_lbp[i][j])\n",
    "        dinow_lbp_hists.append(hist)\n",
    "        dinow_lbp_hists_n.append(hist_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097126b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, figsize=(5, 5))\n",
    "axs[0].plot(dinow_lbp_hists[0], color=\"b\")\n",
    "axs[1].plot(dinow_lbp_hists[10], color=\"b\")\n",
    "axs[2].plot(dinow_lbp_hists[14], color=\"b\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Histograms of LBP Windows.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ac1ece-56df-46bd-bd0a-c3fa065a217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(len(dinow_lbp_hists_n), figsize=(5, 20))\n",
    "# for i in range(len(dinow_lbp_hists_n)):\n",
    "#     axs[i].plot(dinow_lbp_hists_n[i], color=\"b\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c937f-c64f-4a61-9430-9f976f9f7ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dinow_lbp_hists)):\n",
    "    plt.plot(dinow_lbp_hists[i], color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e01b3-8077-459f-9ccd-9ebdf9392e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dinow_lbp_hists_n)):\n",
    "    plt.plot(dinow_lbp_hists_n[i], color=\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab66fcd-3513-469e-b057-1418b4d2183b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp_image = ICV_lbp_grayscale(image_g)\n",
    "# print(lbp_image, lbp_image.shape)\n",
    "# plt.imshow(lbp_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5baab25-28a2-4157-a64f-e71b5cdd6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window_size = 16\n",
    "# hist = ICV_grayscale_histogram(lbp_image)\n",
    "# wh = np.array(ICV_window_histograms(lbp_image, window_size))\n",
    "# width, height = lbp_image.shape\n",
    "# wh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0141a4-f0eb-4a01-b758-ba9a34cec2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(hist, color=\"b\")\n",
    "# plt.xlabel(\"histogram bins\")\n",
    "# plt.ylabel(\"frequency\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044a7b23-3c35-4c4f-9fb1-6983e4ca170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(wh, color=\"b\")\n",
    "# plt.xlabel(\"histogram bins\")\n",
    "# plt.ylabel(\"frequency\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf1526-5d91-46b3-9a37-a691b41ba586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# for i in range(len(wh)):\n",
    "#     plt.plot(wh[i], color=\"b\")\n",
    "#     plt.xlabel(\"histogram bins\")\n",
    "#     plt.ylabel(\"frequency\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d6e95f-6bdd-461c-9fa8-bd41bfb0171d",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cacef19",
   "metadata": {},
   "source": [
    "### Generating Global Descriptors and Classifying Images using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6443f993-884c-4265-bcf3-4758714ae048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_generate_global_descriptors(image_paths, window_size=64):\n",
    "    \"\"\"\n",
    "    This function combines several utility functions to create global descriptor for all images which are given to it. \n",
    "\n",
    "    Parameters: \n",
    "    image_paths -> List[strings]\n",
    "    window_size -> int\n",
    "\n",
    "    Returns:\n",
    "    List[List[int]], Tuple(int, int), Dictionary{string -> List[int]}  \n",
    "    \"\"\"\n",
    "\n",
    "    global_descriptors = []\n",
    "    path_to_desc = {}\n",
    "    # Iterate through all images\n",
    "    for i in image_paths:\n",
    "        # Get the current Image\n",
    "        image = plt.imread(i)\n",
    "        # Convert it to grayscale\n",
    "        image_g = ICV_to_grayscale(image) \n",
    "        # Divide it into non overlapping windows\n",
    "        dinow = ICV_divide_into_non_overlapping_windows(image_g, window_size)\n",
    "        dinow_lbp = []\n",
    "        # Apply LBP to all of the windows for each image and store the results in a list\n",
    "        for j in dinow:\n",
    "            dinow_lbp.append(ICV_lbp_grayscale(j))\n",
    "        dinow_lbp = np.array(dinow_lbp)\n",
    "        dinow_lbp_hists_n = []\n",
    "        # Get normalized histograms for each LBP Window and store it \n",
    "        for k in range(dinow_lbp.shape[0]):\n",
    "            _, hist_n = ICV_grayscale_histogram(dinow_lbp[k])\n",
    "            dinow_lbp_hists_n.append(hist_n)\n",
    "        # Append the histograms togther and then flatten the list containing them to have one sparse list \n",
    "        # which represent the global descriptor for the image \n",
    "        global_descriptors.append(np.array(dinow_lbp_hists_n).flatten())\n",
    "        # Add each image's associated descriptor in a dictionary to help with heatmap creaton\n",
    "        path_to_desc[i] = path_to_desc.get(i, 0) + np.array(dinow_lbp_hists_n).flatten()\n",
    "    return np.array(global_descriptors),  path_to_desc\n",
    "\n",
    "image_paths = [\"face-1.jpg\", \"face-2.jpg\", \"face-3.jpg\", \"car-1.jpg\", \"car-2.jpg\", \"car-3.jpg\"]\n",
    "gd1 = ICV_generate_global_descriptors(image_paths, window_size = 64)\n",
    "gd2 = ICV_generate_global_descriptors(image_paths, window_size = 16)\n",
    "gd3 = ICV_generate_global_descriptors(image_paths, window_size = 128)\n",
    "# gd1[2], gd2[2], gd3[2]\n",
    "gd1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04af50-5d58-45ed-b21b-d6fc97fcf631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_all_global_descriptor_similarities(descriptors):\n",
    "    \"\"\"\n",
    "    Takes a list of all global descriptors and finds the intersection for all combinations of them taken 2 at a time\n",
    "\n",
    "    Parameters: \n",
    "    descriptors -> List[List[int]]\n",
    "\n",
    "    Returns:\n",
    "    intersections -> Dictionary{Tuple(int, int) -> List[int]}\n",
    "    \"\"\"\n",
    "    def ICV_descriptor_intersection(desc1, desc2):\n",
    "        return np.sum(np.minimum(desc1, desc2))\n",
    "\n",
    "    intersections = {}\n",
    "    for i in range(len(descriptors)):\n",
    "        for j in range(len(descriptors)):\n",
    "            if (i,j) not in intersections and (j,i) not in intersections:\n",
    "                if i == j:\n",
    "                    intersections[(i, j)] = 1\n",
    "                    continue\n",
    "                d1 = descriptors[i]\n",
    "                d2 = descriptors[j]\n",
    "                i1 = ICV_descriptor_intersection(d1, d2)\n",
    "                intersections[(i,j)] = i1\n",
    "    return intersections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a91adb-188a-47df-aae6-d7672d7d2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdi1 = ICV_all_global_descriptor_similarities(gd1[0])\n",
    "gdi2 = ICV_all_global_descriptor_similarities(gd2[0])\n",
    "gdi3 = ICV_all_global_descriptor_similarities(gd3[0])\n",
    "\n",
    "gdi1, gdi2, gdi3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba59bfd7-314a-434c-b9db-1ae5e434dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Here I generate a heatmap of the descriptor intersections between images to classify them for window size = 64\n",
    "\n",
    "intersection_data = gdi1\n",
    "\n",
    "num_images = len(image_paths) \n",
    "\n",
    "intersection_matrix = np.zeros((num_images, num_images))\n",
    "\n",
    "for (i, j), value in intersection_data.items():\n",
    "    intersection_matrix[i, j] = value\n",
    "    intersection_matrix[j, i] = value \n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(intersection_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "            xticklabels=[f'Image {i}' for i in range(num_images)], \n",
    "            yticklabels=[f'Image {i}' for i in range(num_images)])\n",
    "\n",
    "plt.title('Global Descriptor Intersection Heatmap')\n",
    "plt.xlabel('Images')\n",
    "plt.ylabel('Images')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Global_Descriptor_Intersection_for_Different_Images_in_DataSet_A.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25147396-8a9d-47da-ae7c-be66e4ac0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Here I generate a heatmap of the descriptor intersections between images for all window sizes at once\n",
    "\n",
    "intersection_data = [gdi1, gdi2, gdi3] # Global Descriptors as Dictionaries for window sizes 64, 16 and 128\n",
    "num_images = len(image_paths)\n",
    "intersection_matrix = np.zeros((num_images, num_images))\n",
    "\n",
    "for k, i_d in enumerate(intersection_data):\n",
    "    for (i, j), value in i_d.items():\n",
    "        intersection_matrix[i, j] = value\n",
    "        intersection_matrix[j, i] = value\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(intersection_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', \n",
    "                xticklabels=[f'Image {i}' for i in range(num_images)], \n",
    "                yticklabels=[f'Image {i}' for i in range(num_images)])\n",
    "    \n",
    "    plt.title('Global Descriptor Intersection Heatmap')\n",
    "    plt.xlabel('Images')\n",
    "    plt.ylabel('Images')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"Global_Descriptor_Intersection_for_Different_Images_in_DataSet_A_Window_{k}.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843eb560",
   "metadata": {},
   "source": [
    "The idea with these heatmaps was to compare all images with each other at once. Here we can treat one image as reference and the other as the one which we want to classify. Based on that the ones which have highest similarity with the same class of images as themselves have correct classifications while ones with high intersections with the opposite classes are Misclassifications. For different window sizes the overall threshold for the score at which a window is a Face or not changes (the smaller the window the higher the score required).  Looking at the Heatmaps above it's evident that:\n",
    "- Descriptors with smaller window sizes capture more information about subtle texture changes in the image which larger window sizes don't allow for. \n",
    "- This type of descriptor seems to perform fairly well for face images (based on higher similarity scores between face images against face images compared to car images against each other).\n",
    "- As can be seen in the heatmap the model is most certain about the similarity of images 1 and 2 and 0 and 2. Thus Image 2 (face-3.jpg) can serve as a good baseline for face images. Similarly for Car images this is true with Image 4 in the heatmap or (car-2.jpg) a similar build type to (car-3.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d1dc22-314f-4ba2-8b06-ab439ddc03ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "face3 = plt.imread(\"face-3.jpg\")\n",
    "car1 = plt.imread(\"car-1.jpg\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(13, 5))\n",
    "axs[0].imshow(face3)\n",
    "axs[1].imshow(car1)\n",
    "fig.suptitle(\"Example Images\", fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "for (i,j) in [(gd1, 64), (gd2, 16), (gd3, 128)]:\n",
    "    i_2 = np.array(i[0][2])\n",
    "    i_3 = np.array(i[0][3])\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 10))\n",
    "    axs[0].plot(i_2)\n",
    "    axs[1].plot(i_3)\n",
    "    fig.suptitle(f\"Associated Global Descriptor Histograms (window size = {j})\", fontsize=20)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
